# 🚁 使用 RL 训练无人机悬停策略

Genesis 支持并行仿真，非常适合高效地训练强化学习（RL）无人机悬停策略。在本教程中，我们将通过一个完整的训练示例，介绍如何获得一个基本的悬停策略，使无人机能够通过到达随机生成的目标点来保持稳定的悬停位置。

这是一个简单且最小的示例，演示了 Genesis 中非常基础的 RL 训练流程，通过以下示例，您将能够快速获得一个可部署到真实无人机的悬停策略。

**注意**：这*不是*一个全面的无人机悬停策略训练流程。它使用简化的奖励项来让您轻松入门，并且没有利用 Genesis 在大批量上的速度优势，因此它仅用于基本演示目的。

**致谢**：本教程的灵感来源于 [Champion-level drone racing using deep reinforcement learning (Nature 2023)](https://www.nature.com/articles/s41586-023-06419-4.pdf)。

## 环境概述

我们首先创建一个 gym 风格的环境（hover-env）。

#### 初始化

`__init__` 函数通过以下步骤设置仿真环境：
1. **控制频率**。
    仿真以 100 Hz 运行，为无人机提供高频控制回路。
2. **场景创建**。
    创建仿真场景，包括无人机和一个静态平面。
3. **目标初始化**。
    初始化一个随机目标点，无人机将尝试到达该点。
4. **奖励注册**。
    奖励函数在配置中定义并注册以指导策略。这些函数将在"奖励"部分中解释。
5. **缓冲区初始化**。
    初始化缓冲区以存储环境状态、观测值和奖励。

#### 重置

`reset_idx` 函数重置指定环境的初始姿态和状态缓冲区。这确保机器人从预定义配置开始，这对于一致的训练至关重要。

#### 步骤

`step` 函数根据策略采取的动作更新环境状态。它包括以下步骤：
1. **动作执行**。
    输入动作将被裁剪到有效范围，重新缩放，并作为调整应用于默认悬停螺旋桨 RPM。
2. **状态更新**。
    检索无人机状态（如位置、姿态和速度）并存储在缓冲区中。
3. **终止检查**。
    终止的环境会自动重置。环境在以下情况下终止：
    - 回合长度超过允许的最大值。
    - 无人机的俯仰或横滚角度超过指定阈值。
    - 无人机的位置超过指定边界。
    - 无人机离地面太近。
4. **奖励计算**。
    根据无人机在到达目标点和保持稳定方面的表现计算奖励。
5. **观测计算**。
    观测值被归一化并返回给策略。用于训练的观测值包括无人机的位置、姿态（四元数）、机体线速度、机体角速度和先前的动作。

#### 奖励

在此示例中，我们使用以下奖励函数来鼓励无人机到达目标点并保持稳定：
- **target**: 鼓励无人机到达随机生成的目标点。
- **smooth**: 鼓励平滑动作并缩小 sim-to-real 差距。
- **yaw**: 鼓励无人机保持稳定的悬停偏航。
- **angular**: 鼓励无人机保持低角速度。
- **crash**: 惩罚无人机坠毁或偏离目标太远。

这些奖励函数结合起来为策略提供全面的反馈，指导其实现稳定准确的悬停行为。

## 训练

在这个阶段，我们已经定义了环境。要使用 PPO 训练无人机悬停策略，请按照以下步骤操作：
1. **安装依赖项**。
    首先，确保您已安装 Genesis，然后使用 `pip` 添加所有必需的 Python 依赖项：
    ```bash
    pip install --upgrade pip
    pip install tensorboard rsl-rl-lib==2.2.4
    ```
2. **运行训练脚本**。
    使用提供的训练脚本开始训练策略。
    ```bash
    python hover_train.py -e drone-hovering -B 8192 --max_iterations 301
    ```
    - `-e drone-hovering`: 将实验名称指定为 "drone-hovering"。
    - `-B 8192`: 将环境数量设置为 8192 以进行并行训练。
    - `--max_iterations 301`: 将最大训练迭代次数指定为 301。
    - `-v`: 可选。启用可视化训练。

    要监控训练过程，启动 TensorBoard：
    ```bash
    tensorboard --logdir logs
    ```
    您应该看到类似这样的训练曲线：
    ```{figure} ../../_static/images/hover_curve.png
    ```
    当启用可视化进行训练时，您将看到：
    ```{figure} ../../_static/images/training.gif
    ```

## 评估

要评估训练好的无人机悬停策略，请按照以下步骤操作：
1. **运行评估脚本**。
    使用提供的评估脚本来评估训练好的策略。
    ```bash
    python hover_eval.py -e drone-hovering --ckpt 300 --record
    ```
    - `-e drone-hovering`: 将实验名称指定为 "drone-hovering"。
    - `--ckpt 300`: 从检查点 300 加载训练好的策略。
    - `--record`: 记录评估并保存无人机表现的视频。
2. **可视化结果**。
    评估脚本将可视化无人机的表现，如果设置了 `--record` 标志，则保存视频。

<video preload="auto" controls="True" width="100%">
<source src="https://github.com/Genesis-Embodied-AI/genesis-doc/raw/main/source/_static/videos/hover_env.mp4" type="video/mp4">
</video>

通过遵循本教程，您将能够使用 Genesis 训练和评估一个基本的无人机悬停策略。玩得开心！
